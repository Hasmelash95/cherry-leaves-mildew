{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation Notebook**"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fulfill Business Requirements 2 - predict if a cherry leaf is healthy or contains powdery mildew.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/cherry_leaves_dataset/cherry_leaves/train\n",
        "* inputs/cherry_leaves_dataset/cherry_leaves/validation\n",
        "* inputs/cherry_leaves_dataset/cherry_leaves/test\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Image Augmentation.\n",
        "* Image distribution plot, train vs validation vs test.\n",
        "* Machine learning model creation and training.\n",
        "* Plotting model performance.\n",
        "* Prediction of a selected image file.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Set Working Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(\"/workspace/cherry-leaves-mildew-detection\")\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Input Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"inputs/cherry_leaves_dataset/cherry_leaves\"\n",
        "train_dir = data_dir + \"/train\"\n",
        "val_dir = data_dir + \"/validation\"\n",
        "test_dir = data_dir + \"/test\""
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Output Directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = \"v2\"\n",
        "file_path = f\"outputs/{version}\"\n",
        "if \"outputs\" in os.listdir(current_dir) and version in os.listdir(current_dir + \"/outputs\"):\n",
        "    print(\"This directory exists, create a new version.\")\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Set Label Names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_dir)\n",
        "print(\"The image labels are\", labels)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Import Image Shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "image_shape = joblib.load(filename=f\"outputs/v1/image_shape_embed.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Label Frequency Per Set"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Distribution Per Label Per Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread\n",
        "\n",
        "df_label_frequency = pd.DataFrame([])\n",
        "for set in [\"train\", \"validation\", \"test\"]:\n",
        "    for label in labels:\n",
        "        count = int(len(os.listdir(data_dir + \"/\" + set + \"/\" + label)))\n",
        "        df_label_frequency = df_label_frequency.append(pd.Series(data={\"Dataset\": set, \n",
        "                                                                       \"Labels\": label,\n",
        "                                                                       \"Frequency\": count}),\n",
        "                                                        ignore_index=True)\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_label_frequency, x=\"Dataset\", y=\"Frequency\", hue=\"Labels\", palette=\"Accent\")\n",
        "plt.title(\"Label Distribution Per Set\")\n",
        "if \"label_distribution_graph.jpg\" not in file_path:\n",
        "    plt.savefig(f\"{file_path}/label_distribution_graph.jpg\")\n",
        "else:\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "colors = sns.color_palette(\"Accent\")\n",
        "\n",
        "df_label_set_frequency = []\n",
        "for set in [train_dir, val_dir, test_dir]:\n",
        "    for label in labels:\n",
        "        count = int(len(os.listdir(set + \"/\" + label)))\n",
        "        df_label_set_frequency.append(count)\n",
        "\n",
        "set_label = [\"train_healthy\", \"train_mildew\", \"val_healthy\", \"val_mildew\", \"test_healthy\", \"test_mildew\"]\n",
        "\n",
        "plt.pie(df_label_set_frequency, labels=set_label, colors=colors, autopct=\"%1.1f%%\")\n",
        "plt.title(\"Label Distribution Per Set\")\n",
        "if \"label_distribution_pie_plot.jpg\" not in file_path:\n",
        "    plt.savefig(f\"{file_path}/label_distribution_pie_plot.jpg\")\n",
        "else:\n",
        "    plt.show()\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data is distrubted between the set in a 70:15:15 split. There are an equal number of healthy and powdery images so the dataset is balanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Image Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Initialising ImageDataGenerator\n",
        "augmented_images = ImageDataGenerator(rotation_range=25,\n",
        "                                      width_shift_range=0.2,\n",
        "                                      height_shift_range=0.2,\n",
        "                                      shear_range=0.2,\n",
        "                                      zoom_range=0.2,\n",
        "                                      horizontal_flip=True,\n",
        "                                      vertical_flip=True,\n",
        "                                      fill_mode=\"nearest\",\n",
        "                                      rescale=1./255\n",
        "                                      )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augment Training Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set batch size the data will be looped over\n",
        "batch_size = 20\n",
        "# Augmented training data\n",
        "train_set = augmented_images.flow_from_directory(train_dir,\n",
        "                                                 target_size=image_shape[:2],\n",
        "                                                 color_mode=\"rgb\",\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 class_mode=\"binary\",\n",
        "                                                 shuffle=True\n",
        "                                                 )\n",
        "train_set.class_indices"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augment Validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set batch size the data will be looped over\n",
        "batch_size = 20\n",
        "# Augmented training data\n",
        "val_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_dir,\n",
        "                                                                 target_size=image_shape[:2],\n",
        "                                                                 color_mode=\"rgb\",\n",
        "                                                                 batch_size=batch_size,\n",
        "                                                                 class_mode=\"binary\",\n",
        "                                                                 shuffle=False\n",
        "                                                                 )\n",
        "val_set.class_indices"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Augment Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set batch size the data will be looped over\n",
        "batch_size = 20\n",
        "# Augmented training data\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_dir,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode=\"rgb\",\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode=\"binary\",\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "test_set.class_indices"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Plot Augmented Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sets = {\"Train\": train_set, \"Validation\": val_set, \"Test\": test_set}\n",
        "for name, set in sets.items():\n",
        "    print(f\"{name} Set\")\n",
        "    for _ in range(5):\n",
        "        X, y = set.next()\n",
        "        print(X.shape)\n",
        "        plt.imshow(X[0])\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save train set class indices\n",
        "if \"train_set_class_indices.pkl\" not in file_path:\n",
        "    joblib.dump(value=train_set.class_indices, filename=f\"{file_path}/train_set_class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPool2D\n",
        "\n",
        "n_labels = 2\n",
        "\n",
        "def create_tf_model(input_shape, n_labels):\n",
        "    \"\"\"\n",
        "    Function to define a sequential model which will\n",
        "    arrange a sequence of layers in the neural network.\n",
        "    Parameters are - input shape, which will be the image \n",
        "    shape and n_labels, where n is the number of labels.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    \n",
        "    # Apply filters to the images to capture dominant patterns\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3,3), input_shape=input_shape, activation=\"relu\",))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=16, kernel_size=(3,3), input_shape=input_shape, activation=\"relu\",))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=8, kernel_size=(3,3), input_shape=input_shape, activation=\"relu\",))\n",
        "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
        "\n",
        "    # Flatten the image matrix into a single list of all values\n",
        "    model.add(Flatten())\n",
        "    \n",
        "    model.add(Dense(128, activation=\"relu\"))\n",
        "    # Add a dropout layer to reduce overfitting\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    model.add(Dense(1, activation=\"sigmoid\"))\n",
        "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) \n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model(input_shape=image_shape, n_labels=n_labels)\n",
        "model.summary()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=3)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(train_set,\n",
        "          epochs=25,\n",
        "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "          validation_data = val_set,\n",
        "          callbacks=early_stopping,\n",
        "          verbose=1)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if \"mildew_detector.h5\" not in {file_path}:\n",
        "    model.save(f\"{file_path}/mildew_detector.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"darkgrid\")\n",
        "\n",
        "losses[[\"loss\", \"val_loss\"]].plot(style=\".-\")\n",
        "plt.title(\"Loss\")\n",
        "if \"model_loss.jpg\" not in {file_path}:\n",
        "    plt.savefig(f\"{file_path}/model_loss.jpg\")\n",
        "plt.show()\n",
        "\n",
        "losses[[\"accuracy\", \"val_accuracy\"]].plot(style=\".-\")\n",
        "plt.title(\"Accuracy\")\n",
        "if \"model_accuracy.png\" not in {file_path}:\n",
        "    plt.savefig(f\"{file_path}/model_accuracy.jpg\")\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(f\"{file_path}/mildew_detector.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate model on test set\n",
        "evaluate_test = model.evaluate(test_set)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This value exceeds the requirement on 97% accuracy. Therefore, the model successfully fulfils the business requirements."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save evaluation\n",
        "if \"test_evaluation.pkl\" not in file_path: \n",
        "    joblib.dump(value=evaluate_test, filename=f\"{file_path}/test_evaluation.pkl\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict on Unseen Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load a random image as pil\n",
        "index = 300\n",
        "\n",
        "label=labels[1]\n",
        "\n",
        "pil_image = image.load_img(test_dir + \"/\" + label + \"/\" + os.listdir(test_dir + \"/\" + label)[index],\n",
        "                           target_size=image_shape, color_mode=\"rgb\")\n",
        "print(f\"Image Shape: {pil_image.size}\\nImage Mode: {pil_image.mode}\")\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert image into array\n",
        "test_image = image.img_to_array(pil_image)\n",
        "test_image = np.expand_dims(test_image, axis=0)/255\n",
        "print(test_image.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "probability = model.predict(test_image)[0, 0]\n",
        "\n",
        "class_indices = joblib.load(filename=f\"{file_path}/train_set_class_indices.pkl\")\n",
        "# Reverse the key value pairs to map number to label\n",
        "label_map = {value: key for key, value in class_indices.items()}\n",
        "pred_class = label_map[probability > 0.5]\n",
        "\n",
        "if pred_class == probability:\n",
        "    probability = 1 - probability\n",
        "\n",
        "print(f\"The predicted probability value is {probability} so the predicted class is {pred_class}.\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n",
        "\n",
        "* The model has exceeded the business requirement of 97% prediction accuracy. The model can accurately predict whether an image can be classified as healthy or containing powdery mildew. \n",
        "* The Loss and Accuracy plots show the data hasn't overfitted, as the validation and training sets follow a similar path. Therefore the model can be used to predict unseen data. "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
